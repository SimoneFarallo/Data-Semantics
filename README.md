# Data-Semantics
Distributional semantics research area studies the distributional properties of linguistic items.
The basic idea of distributional semantics is that words that are used and occur in the same contexts tend to have similar meanings.

Word embeddings models aim to quantify semantic similarities between linguistic items based on their distributional properties in large samples of language data.
The context of a word is defined by its nearest words: "a word is characterized by the company it keeps" (John Rupert Firth, 1957).


We will use word embeddings models to analyse the sacred texts of the 4 most popular religions. In particular we will focus on the following questions:
1. By exploring the context of some interesting words, is it possible to hypothesise certain specific characteristics of a religion?
2. By using embeddings trained on aligned corpora, is it possible to link important characters of different religions?
3. By exploring the context of words referred to fundamental religious concepts is it possible to find emotional character associated with a religion?


DISCLAIMER: The results are not very reliable and consistent because of the models used and the computational limitation of our computers.
The university project is to understand and analyze W2VEC models and what the word semantics means in the data world.
